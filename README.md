# Analyzing-10GB-of-Data

Provisioning a Spark cluster on AWS Elastic Map Reduce (EMR) and connecting it to a Jupyter Notebook. I used PySpark to deal with this large datasets.

The goal is to analyze a subset of Yelp's business, review, and user data. I downloaded it from Kaggle.com and uploaded it to my AWS S3 bucket

## Files

Code and analysis is provided in both ipynb and pdf formats.

## AWS EMR Cluster Configuration

![cluster_configuration](https://user-images.githubusercontent.com/60671004/121269341-a63ea780-c88d-11eb-8977-81902687012e.png)
